import json
import logging
import os
import re
import time
import base64
import numpy as np
import argparse
import requests
import traceback
import io

from datetime import datetime
from pathlib import Path
from typing import Dict, List, Optional, Tuple
from PIL import Image

from gym_wrapper import CoopCommandGymEnv

# Try to import video processing libraries
try:
    import cv2
    CV2_AVAILABLE = True
except ImportError:
    CV2_AVAILABLE = False

try:
    from moviepy.editor import VideoFileClip, AudioFileClip, CompositeAudioClip
    import moviepy.config as moviepy_config
    MOVIEPY_AVAILABLE = True
except ImportError:
    MOVIEPY_AVAILABLE = False

# Setup logging
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(levelname)s - %(message)s',
    handlers=[
        logging.FileHandler('qwen_eval.log'),
        logging.StreamHandler()
    ]
)
logger = logging.getLogger(__name__)

os.environ['SDL_AUDIODRIVER'] = 'dummy'
os.environ['SDL_VIDEODRIVER'] = 'dummy'

# APIé…ç½®
API_BASE  = ""
API_KEY   = ""
MODEL_CHAT = "gemini-2.5-pro"

# API Configurations
API_CONFIGS = {
    "qwen": {
        "api_key_env": "QWEN_API_KEY",
        "base_url": API_BASE,
        "default_model": MODEL_CHAT,
        "vision_support": True,
        "audio_support": True
    },
    "openai": {
        "api_key_env": "OPENAI_API_KEY", 
        "base_url": None,
        "default_model": "gpt-4o",
        "vision_support": True,
        "audio_support": False
    }
}

class MultiProviderEvaluator:
    """Multi-provider evaluator for cooperative command game supporting Qwen and OpenAI."""
    
    def __init__(self, difficulty: str = "normal", seed_index: int = 0, 
                 max_rounds: Optional[int] = 100, enable_stream: bool = True,
                 save_media: bool = True, deterministic_commands: bool = True,
                 api_provider: str = "qwen", model_name: Optional[str] = None,
                 input_mode: str = "video", include_vector_text: bool = True,
                 enhanced_video: bool = False, video_fps: float = 0.5, 
                 audio_duration_per_frame: float = 3.0, num_episodes: int = 10):
        """
        Initialize the multi-provider evaluator.
        """
        self.difficulty = difficulty
        self.seed_index = seed_index
        self.max_rounds = max_rounds
        self.enable_stream = enable_stream
        self.save_media = save_media
        self.deterministic_commands = deterministic_commands
        self.api_provider = api_provider.lower()
        self.input_mode = input_mode.lower()
        self.include_vector_text = include_vector_text
        self.enhanced_video = enhanced_video
        self.video_fps = video_fps
        self.audio_duration_per_frame = audio_duration_per_frame
        self.num_episodes = num_episodes  # æ–°å¢žï¼šepisodeæ•°é‡
        
        # Validate input mode
        if self.input_mode not in ["image_audio", "video"]:
            raise ValueError(f"Unsupported input mode: {input_mode}. Choose from: ['image_audio', 'video']")
        
        # åˆå§‹åŒ–APIé…ç½®
        self.api_base = API_BASE
        self.api_key = API_KEY
        self.model_name = model_name or MODEL_CHAT
        
        # åˆå§‹åŒ–session
        self.session = requests.Session()
        
        # Create output directory for this evaluation
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")

        output_root = "outputs"
        os.makedirs(output_root, exist_ok=True)
        self.output_dir = Path(f"{output_root}/{self.api_provider}_eval_{difficulty}_seed{seed_index}_{num_episodes}ep_{timestamp}")
        if self.save_media:
            self.output_dir.mkdir(exist_ok=True)
            self.images_dir = self.output_dir / "images"
            self.audio_dir = self.output_dir / "audio"
            self.videos_dir = self.output_dir / "videos"
            self.responses_dir = self.output_dir / "responses"
            self.images_dir.mkdir(exist_ok=True)
            self.audio_dir.mkdir(exist_ok=True)
            self.videos_dir.mkdir(exist_ok=True)
            self.responses_dir.mkdir(exist_ok=True)
        
        # æ–°å¢žï¼šä¸ºæ¯ä¸ªepisodeåˆ›å»ºå­ç›®å½•
        self.episode_dirs = {}
        if self.save_media:
            for ep in range(num_episodes):
                ep_dir = self.output_dir / f"episode_{ep:02d}"
                ep_dir.mkdir(exist_ok=True)
                self.episode_dirs[ep] = {
                    "root": ep_dir,
                    "images": ep_dir / "images",
                    "audio": ep_dir / "audio", 
                    "videos": ep_dir / "videos",
                    "responses": ep_dir / "responses"
                }
                # åˆ›å»ºå­ç›®å½•
                for subdir in ["images", "audio", "videos", "responses"]:
                    self.episode_dirs[ep][subdir].mkdir(exist_ok=True)
        
        # ä¸åœ¨åˆå§‹åŒ–æ—¶åˆ›å»ºçŽ¯å¢ƒï¼Œå°†åœ¨æ¯ä¸ªepisodeå¼€å§‹æ—¶åˆ›å»º
        self.env = None
        
        # Results tracking - ä¿®æ”¹ä¸ºæ”¯æŒå¤šepisode
        self.results = {
            "config": {
                "difficulty": difficulty,
                "seed_index": seed_index,
                "max_rounds": max_rounds,
                "api_provider": self.api_provider,
                "model": self.model_name,
                "input_mode": self.input_mode,
                "include_vector_text": self.include_vector_text,
                "enhanced_video": self.enhanced_video,
                "video_fps": self.video_fps,
                "audio_duration_per_frame": self.audio_duration_per_frame,
                "vision_support": True,
                "num_episodes": num_episodes,  # æ–°å¢ž
                "timestamp": datetime.now().isoformat(),
                "output_directory": str(self.output_dir) if self.save_media else None
            },
            "episodes": [],  # ä¿®æ”¹ï¼šå­˜å‚¨æ¯ä¸ªepisodeçš„ç»“æžœ
            "summary_stats": {},  # æ–°å¢žï¼šæ±‡æ€»ç»Ÿè®¡
            "media_files": {
                "images": [],
                "audio": [],
                "videos": [],
                "responses": []
            },
            "command_compliance": {
                "total_turns": 0,
                "valid_single_commands": 0,
                "multiple_command_violations": 0,
                "no_command_found": 0,
                "compliance_rate": 0.0
            }
        }
        
        # Command types for reference
        self.command_types = ["move", "attack", "defend", "recon", "status"]
        
        # Store member list for multi-member commands
        self._last_member_list = []
        
        # å¢žå¼ºç³»ç»Ÿæç¤º - ä¸ºå¤šepisodeè¯„ä¼°ä¼˜åŒ–
        command_reliability_note = """
âš™ï¸ COMMAND EXECUTION:
- Commands execute deterministically - all valid commands will succeed
- Focus on strategic positioning and optimal task assignment
- No need to account for random command failures

""" if deterministic_commands else """
âš™ï¸ COMMAND EXECUTION:
- Commands may randomly fail based on team member capability and status
- Scout: 85% success rate, Heavy: 75%, Medic: 90%, Engineer: 80%, Sniper: 70%
- Injured or low-health members have reduced success rates
- Plan for potential command failures and have backup strategies

"""
        
        # Build media description based on input mode
        if self.input_mode == "video":
            if self.enhanced_video:
                media_description = f"""- Video: Visual sequence with integrated audio (FPS: {actual_fps}, Audio per frame: {self.audio_duration_per_frame}s)
  Shows game state progression and team member movements with synchronized voice communications"""
            else:
                media_description = "- Video: Visual sequence showing game state progression and team member movements over time"
        else:
            media_description = """- Audio: Voice reports from team members about discoveries, status changes
- Image: Visual representation of current game state"""

        # Build information sources section
        if self.include_vector_text:
            info_sources = f"""ðŸ“Š INFORMATION PROVIDED:
- Vector: Team member states (health, status, position) + global info (rounds remaining, normalized score)
{media_description}
- Discovery hints: Clues about nearby hidden objectives"""
        else:
            info_sources = f"""ðŸ“Š INFORMATION PROVIDED:
{media_description}
- Discovery hints: Clues about nearby hidden objectives

âš ï¸ NOTE: Vector information is available visually - interpret team states from the visual input."""

        self.system_prompt = f"""
You are commanding a military team in a cooperative mission. You MUST provide EXACTLY ONE command per turn.

âŒ FORBIDDEN: Multiple commands like "COMMAND: 0 move 20 30" AND "COMMAND: 1 recon 40 50"
âœ… CORRECT: Only one command like "COMMAND: 0 move 20 30"

If you provide more than one command, the system will ERROR and use a default command instead.

KEY GAME MECHANICS:

{command_reliability_note}

ðŸŽ¯ HIDDEN OBJECTIVES:
- Some objectives are HIDDEN and not visible initially
- You must EXPLORE different areas to discover hidden objectives
- Scout team members have higher discovery probability (80% vs 40%)
- Send scouts to unexplored areas to find new objectives
- Discovery hints may indicate "unusual activity" in areas with hidden objectives

âš ï¸ MOVEMENT UNCERTAINTY:
- Team members DO NOT move to exact coordinates you specify
- Movement has ERROR based on:
  * Role precision (Scout: low error, Heavy: high error)
  * Health status (injured = more error)
  * Movement distance (longer moves = more error)
- Expect actual positions to deviate from your targets
- Plan for imprecise movement in your strategy

{info_sources}

ðŸŽ® STRATEGIC CONSIDERATIONS:
- Balance exploration (finding hidden objectives) vs completion (finishing known objectives)
- Use scouts for exploration and discovery
- Account for movement errors in positioning
- Monitor team health and status for optimal assignment
- Hidden objectives may have high score values - worth discovering!

ðŸš¨ COMMAND FORMAT - PROVIDE EXACTLY ONE OF THESE:

**Individual Command (one member):**
COMMAND: [member_id] [action] [x] [y]

**Team Command (all members together):**
COMMAND: all [action] [x] [y]

**Multi-member Command (specific members together):**
COMMAND: 0,1,2 [action] [x] [y]

**Available Actions:** move, attack, defend, recon, status
**Coordinates:** x, y: 0-100 (actual position will vary due to movement error)

EXAMPLES OF CORRECT RESPONSES:
âœ… "Based on the current situation, I'll send the scout to explore. COMMAND: 0 recon 25 30"
âœ… "The team should move together to the objective. COMMAND: all move 45 20"
âœ… "Two scouts should explore this area. COMMAND: 0,1 recon 70 80"

EXAMPLES OF INCORRECT RESPONSES (WILL CAUSE ERRORS):
âŒ "COMMAND: 0 move 25 30" followed by "COMMAND: 1 recon 45 20"
âŒ Multiple command lines in any form
âŒ Suggesting multiple commands for "efficient coordination"

ðŸš¨ FINAL REMINDER: ONE COMMAND ONLY! ðŸš¨
- Analyze the situation thoroughly
- Choose the SINGLE most important action
- Provide exactly ONE command
- Plan step-by-step across multiple turns, not all at once

Provide your strategic analysis, then end with exactly ONE command.
"""

    def encode_file_to_base64(self, file_path: str) -> str:
        """ç¼–ç æ–‡ä»¶ä¸ºbase64å­—ç¬¦ä¸²"""
        try:
            with open(file_path, "rb") as file:
                return base64.b64encode(file.read()).decode('utf-8')
        except Exception as e:
            logger.error(f"æ–‡ä»¶ç¼–ç å¤±è´¥ {file_path}: {e}")
            return ""

    def _get_state_description(self, observation) -> str:
        """Create human-readable state description from observation."""
        try:
            # Handle both dict and array observation formats
            if isinstance(observation, dict):
                # Multi-modal observation format
                vector_obs = observation['vector']
                audio_data = json.loads(observation.get('audio', '[]')) if isinstance(observation.get('audio'), str) else []
                has_image = 'image' in observation
            else:
                # Simple vector observation format
                vector_obs = observation
                audio_data = []
                has_image = False
            
            # Ensure vector_obs is a numpy array
            if hasattr(vector_obs, 'shape'):
                vector_obs = vector_obs.flatten()  # Flatten if multi-dimensional
            
            # Parse vector observation
            num_members = (len(vector_obs) - 2) // 4
            description = [f"Team size: {num_members}"]
            
            # Member states
            for i in range(num_members):
                base_idx = i * 4
                health = float(vector_obs[base_idx])
                status_code = int(float(vector_obs[base_idx + 1]))
                x, y = float(vector_obs[base_idx + 2]), float(vector_obs[base_idx + 3])
                
                status_names = ["idle", "moving", "attacking", "defending", "recon", "dead", "injured"]
                status = status_names[status_code] if status_code < len(status_names) else "unknown"
                
                description.append(f"Member {i}: {health:.0f}% health, {status}, at ({x:.0f},{y:.0f})")
            
            # Global state
            rounds_remaining = int(float(vector_obs[-2]))
            score_normalized = float(vector_obs[-1])
            description.append(f"Rounds remaining: {rounds_remaining}")
            description.append(f"Score: {score_normalized:.1f}/100")
            
            # Audio events
            if audio_data:
                description.append(f"Audio: {', '.join(str(msg) for msg in audio_data)}")
            
            # Visual info
            if has_image:
                description.append("Visual: Game state image available")
            
            # Check for video in observation
            if isinstance(observation, dict) and observation.get('video') is not None:
                description.append("Video: Game state video sequence available")
            
            return "\n".join(description)
            
        except Exception as e:
            logger.error(f"Error creating state description: {e}")
            logger.error(f"Observation type: {type(observation)}")
            if hasattr(observation, 'shape'):
                logger.error(f"Observation shape: {observation.shape}")
            elif isinstance(observation, dict):
                logger.error(f"Observation keys: {list(observation.keys())}")
            return "State parsing failed"

    def extract_frames_to_base64_from_file(self, video_file_path):
        """
        Extract one frame per 0.5 second from a video file and convert them to Base64
        """
        base64_frames = []

        try:
            # Load the video directly from the file path
            clip = VideoFileClip(video_file_path)
            
            # Get the duration of the video in seconds
            duration = clip.duration
            
            # Use numpy.arange to generate timestamps at 0.5-second intervals
            timestamps = np.arange(0, duration, 0.5)
            
            # Extract frames at each timestamp
            for t in timestamps:
                frame = clip.get_frame(t) # (H, W ,C)
                
                # Convert the frame to a PIL Image
                image = Image.fromarray(frame.astype('uint8'))
                
                # Create a BytesIO object to hold the image data
                buffered = io.BytesIO()
                image.save(buffered, format='JPEG')
                
                # Encode the image data to Base64
                base64_frame = base64.b64encode(buffered.getvalue()).decode('utf-8')
                base64_frames.append(base64_frame)
                
            clip.close()
        
        except Exception as e:
            print(f"Error processing video {video_file_path}: {e}")
            
        return base64_frames

    def extract_frames_from_base64_video(self, video_base64):
        """
        Extract frames from base64 encoded video data
        """
        base64_frames = []
        
        try:
            # Decode base64 video data
            video_bytes = base64.b64decode(video_base64)
            
            # Save to temporary file
            import tempfile
            with tempfile.NamedTemporaryFile(suffix='.mp4', delete=False) as temp_file:
                temp_file.write(video_bytes)
                temp_video_path = temp_file.name
            
            # Extract frames from temporary file
            base64_frames = self.extract_frames_to_base64_from_file(temp_video_path)
            
            # Clean up temporary file
            os.unlink(temp_video_path)
            
        except Exception as e:
            print(f"Error extracting frames from base64 video: {e}")
            
        return base64_frames

    def _build_messages(self, observation, step: int, video_path: Optional[str] = None, 
                       audio_path: Optional[str] = None, image_path: Optional[str] = None) -> List[Dict]:
        """æž„å»ºåŒ…å«å¤šæ¨¡æ€å†…å®¹çš„æ¶ˆæ¯"""
        try:
            # æž„å»ºåŸºç¡€æ–‡æœ¬å†…å®¹
            if self.include_vector_text:
                state_desc = self._get_state_description(observation)
                base_text = f"""Current game state:
{state_desc}

ðŸš¨ðŸš¨ðŸš¨ CRITICAL REMINDER: EXACTLY ONE COMMAND ONLY! ðŸš¨ðŸš¨ðŸš¨

You MUST provide exactly ONE command in your response. Multiple commands will cause SYSTEM ERRORS!

âŒ DO NOT DO THIS: Provide multiple "COMMAND:" lines
âœ… DO THIS: Provide exactly one "COMMAND:" line

Choose the SINGLE most important action for this turn. You can plan additional moves for future turns.

Available inputs:
- Vector: Team member states (health, status, position) + global info (rounds remaining, normalized score)
- Video: Visual sequence showing game state progression
- Audio: Tactical guidance and team communications
- Discovery hints: Clues about nearby hidden objectives

Analyze the situation and provide your ONE command."""
            else:
                base_text = """ðŸš¨ðŸš¨ðŸš¨ CRITICAL REMINDER: EXACTLY ONE COMMAND ONLY! ðŸš¨ðŸš¨ðŸš¨

You MUST provide exactly ONE command in your response. Multiple commands will cause SYSTEM ERRORS!

âŒ DO NOT DO THIS: Provide multiple "COMMAND:" lines
âœ… DO THIS: Provide exactly one "COMMAND:" line

Choose the SINGLE most important action for this turn. You can plan additional moves for future turns.

Available inputs:
- Video: Visual sequence showing game state progression
- Audio: Tactical guidance and team communications
- Discovery hints: Clues about nearby hidden objectives

âš ï¸ NOTE: Vector information is available visually - interpret team states from the visual input.

Analyze the situation and provide your ONE command."""

            content = [{
                "type": "text",
                "text": base_text
            }]
            
            # ðŸŽ¯ ä¿®æ”¹ï¼šå¤„ç†è§†é¢‘æ•°æ® - æŠ½å¸§è½¬æ¢ä¸ºå›¾åƒåºåˆ—
            if isinstance(observation, dict) and observation.get('video'):
                video_data = observation['video']
                if isinstance(video_data, str) and video_data:
                    try:
                        # æ£€æµ‹è§†é¢‘æ ¼å¼å¹¶è¿›è¡ŒæŠ½å¸§
                        video_bytes_test = base64.b64decode(video_data[:100])
                        is_actual_video = (video_bytes_test[4:12] == b'ftypmp4' or 
                                         video_bytes_test[4:12] == b'ftypisom' or
                                         video_bytes_test[4:8] == b'ftyp')
                        
                        if is_actual_video and MOVIEPY_AVAILABLE:
                            # æ˜¯çœŸå®žè§†é¢‘ï¼Œè¿›è¡ŒæŠ½å¸§
                            print(f"ðŸŽ¬ æ£€æµ‹åˆ°è§†é¢‘æ•°æ®ï¼Œå¼€å§‹æŠ½å¸§å¤„ç†...")
                            video_frames = self.extract_frames_from_base64_video(video_data)
                            
                            if video_frames:
                                # æ·»åŠ å¸§åºåˆ—è¯´æ˜Ž
                                frame_description = f"The following {len(video_frames)} images show the sequence of the game being played (one frame every 0.5 seconds):"
                                content.append({"type": "text", "text": frame_description})
                                
                                # æ·»åŠ æ¯ä¸€å¸§å›¾ç‰‡
                                for i, frame_b64 in enumerate(video_frames):
                                    content.append({
                                        "type": "image_url",
                                        "image_url": {
                                            "url": f"data:image/jpeg;base64,{frame_b64}"
                                        }
                                    })
                                
                                print(f"âœ… å·²æ·»åŠ  {len(video_frames)} ä¸ªè§†é¢‘å¸§åˆ°æ¶ˆæ¯ä¸­")
                            else:
                                print("âš ï¸ è§†é¢‘æŠ½å¸§å¤±è´¥ï¼Œå›žé€€åˆ°å•å¸§å¤„ç†")
                                # å›žé€€åˆ°å•å¸§å›¾åƒ
                                content.append({
                                    "type": "image_url",
                                    "image_url": {
                                        "url": f"data:image/jpeg;base64,{video_data}"
                                    }
                                })
                                logger.info("âœ… å›žé€€å›¾åƒæ•°æ®å·²æ·»åŠ åˆ°æ¶ˆæ¯ä¸­")
                        elif is_actual_video and not MOVIEPY_AVAILABLE:
                            print("âš ï¸ MoviePyä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡Œè§†é¢‘æŠ½å¸§ï¼Œè·³è¿‡è§†é¢‘è¾“å…¥")
                        else:
                            # ä¸æ˜¯è§†é¢‘ï¼Œå½“ä½œå›¾åƒå¤„ç†
                            content.append({
                                "type": "image_url",
                                "image_url": {
                                    "url": f"data:image/jpeg;base64,{video_data}"
                                }
                            })
                            logger.info("âœ… å›¾åƒæ•°æ®å·²æ·»åŠ åˆ°æ¶ˆæ¯ä¸­")
                    except Exception as e:
                        logger.warning(f"è§†é¢‘/å›¾åƒæ•°æ®å¤„ç†å¤±è´¥: {e}")
            
            # æ·»åŠ è§†é¢‘æ–‡ä»¶è·¯å¾„å¤„ç†ï¼ˆå¦‚æžœæœ‰ä¿å­˜çš„è§†é¢‘æ–‡ä»¶ï¼‰
            elif video_path and os.path.exists(video_path) and MOVIEPY_AVAILABLE:
                print(f"ðŸŽ¬ æ­£åœ¨ä»Žè§†é¢‘æ–‡ä»¶ä¸­æŠ½å¸§: {video_path}")
                video_frames = self.extract_frames_to_base64_from_file(video_path)
                
                if video_frames:
                    # æ·»åŠ å¸§åºåˆ—è¯´æ˜Ž
                    frame_description = f"The following {len(video_frames)} images show the sequence of the game being played (one frame every 0.5 seconds):"
                    content.append({"type": "text", "text": frame_description})
                    
                    # æ·»åŠ æ¯ä¸€å¸§å›¾ç‰‡
                    for i, frame_b64 in enumerate(video_frames):
                        content.append({
                            "type": "image_url",
                            "image_url": {
                                "url": f"data:image/jpeg;base64,{frame_b64}"
                            }
                        })
                    
                    print(f"âœ… å·²æ·»åŠ  {len(video_frames)} ä¸ªè§†é¢‘å¸§åˆ°æ¶ˆæ¯ä¸­")
                else:
                    print("âš ï¸ è§†é¢‘æŠ½å¸§å¤±è´¥ï¼Œè·³è¿‡è§†é¢‘è¾“å…¥")
            elif video_path and os.path.exists(video_path) and not MOVIEPY_AVAILABLE:
                print("âš ï¸ MoviePyä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡Œè§†é¢‘æŠ½å¸§")
            
            # æ·»åŠ å›¾åƒï¼ˆå¦‚æžœæœ‰ä¸”æ²¡æœ‰è§†é¢‘ï¼‰
            elif isinstance(observation, dict) and observation.get('image') is not None:
                image_data = observation['image']
                if isinstance(image_data, str):
                    image_base64 = image_data
                elif hasattr(image_data, 'shape'):
                    from PIL import Image
                    import io
                    
                    if len(image_data.shape) == 3:
                        image_pil = Image.fromarray(image_data.astype(np.uint8))
                        buffer = io.BytesIO()
                        image_pil.save(buffer, format='JPEG', quality=85)
                        image_base64 = base64.b64encode(buffer.getvalue()).decode('utf-8')
                    else:
                        image_base64 = None
                else:
                    image_base64 = None
                
                if image_base64:
                    content.append({
                        "type": "image_url",
                        "image_url": {
                            "url": f"data:image/jpeg;base64,{image_base64}"
                        }
                    })
                    logger.info("âœ… å›¾åƒæ•°æ®å·²æ·»åŠ åˆ°æ¶ˆæ¯ä¸­")
            
            # æž„å»ºæ¶ˆæ¯åˆ—è¡¨
            messages = [
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": content}
            ]
            
            # ðŸŽ¯ æ·»åŠ éŸ³é¢‘æ•°æ®å¤„ç†ï¼ˆä¿æŒåŽŸæœ‰é€»è¾‘ï¼‰
            if isinstance(observation, dict) and observation.get('audio'):
                audio_data = observation['audio']
                
                try:
                    if isinstance(audio_data, str):
                        # å°è¯•ä½œä¸ºbase64éŸ³é¢‘æ•°æ®å¤„ç†
                        if not audio_data.startswith('{') and len(audio_data) > 1000:
                            try:
                                # éªŒè¯æ˜¯å¦ä¸ºæœ‰æ•ˆçš„base64éŸ³é¢‘
                                test_decode = base64.b64decode(audio_data[:100])
                                
                                # æ·»åŠ éŸ³é¢‘åˆ°æ¶ˆæ¯ä¸­
                                messages[1]["content"].append({
                                    "type": "input_audio",
                                    "input_audio": {
                                        "data": audio_data,
                                        "format": "mp3",
                                    },
                                })
                                logger.info("âœ… Base64éŸ³é¢‘æ•°æ®å·²æ·»åŠ åˆ°æ¶ˆæ¯ä¸­")
                                
                            except Exception as audio_error:
                                logger.warning(f"éŸ³é¢‘æ•°æ®å¤„ç†å¤±è´¥: {audio_error}")
                                # ä½œä¸ºæ–‡æœ¬å¤„ç†
                                messages[1]["content"][0]["text"] += f"\n\nðŸŽ¤ AUDIO INFO: {audio_data[:200]}..."
                        
                        elif audio_data.startswith('{'):
                            # JSONæ ¼å¼çš„éŸ³é¢‘æŒ‡å¯¼
                            try:
                                audio_json = json.loads(audio_data)
                                if audio_json.get("guidance"):
                                    guidance_text = audio_json["guidance"]
                                    messages[1]["content"][0]["text"] += f"\n\nðŸŽ¤ AUDIO GUIDANCE: {guidance_text}"
                                    
                                    # å¦‚æžœæœ‰å›¢é˜Ÿé€šä¿¡ï¼Œä¹Ÿæ·»åŠ 
                                    if audio_json.get("team_communications"):
                                        comms = audio_json["team_communications"]
                                        if comms:
                                            comm_texts = []
                                            for comm in comms:
                                                if isinstance(comm, dict) and comm.get("message"):
                                                    comm_texts.append(comm["message"])
                                                elif isinstance(comm, str):
                                                    comm_texts.append(comm)
                                            
                                            if comm_texts:
                                                messages[1]["content"][0]["text"] += f"\nðŸ—£ï¸ TEAM COMMUNICATIONS: {'; '.join(comm_texts[:3])}"
                                
                                logger.info("âœ… éŸ³é¢‘æŒ‡å¯¼å·²æ·»åŠ ä¸ºæ–‡æœ¬")
                            except json.JSONDecodeError as e:
                                logger.warning(f"éŸ³é¢‘JSONè§£æžå¤±è´¥: {e}")
                        else:
                            # æ™®é€šæ–‡æœ¬éŸ³é¢‘ä¿¡æ¯
                            messages[1]["content"][0]["text"] += f"\n\nðŸŽ¤ AUDIO INFO: {audio_data}"
                            logger.info("âœ… éŸ³é¢‘æ–‡æœ¬ä¿¡æ¯å·²æ·»åŠ ")
                
                except Exception as e:
                    logger.warning(f"éŸ³é¢‘å¤„ç†é”™è¯¯: {e}")
            
            return messages
            
        except Exception as e:
            logger.error(f"æ¶ˆæ¯æž„å»ºå¤±è´¥: {e}")
            # è¿”å›žåŸºæœ¬æ¶ˆæ¯
            return [
                {"role": "system", "content": self.system_prompt},
                {"role": "user", "content": [{"type": "text", "text": "Analyze the situation and provide your ONE command."}]}
            ]

    def _query_model(self, observation, step: int) -> Tuple[str, np.ndarray, Dict]:
        """Query the model with current observation using your specified API format"""
        try:
            # Initialize media_paths with all expected keys
            media_paths = {
                "video": None,
                "audio": None,
                "image": None,
                "response": None,
                "api_input": None
            }
            
            # Handle video content
            if isinstance(observation, dict) and 'video' in observation:
                video_path = self._save_video(observation['video'], step)
                if video_path:
                    media_paths['video'] = video_path
            
            # Handle audio content
            if isinstance(observation, dict) and 'audio' in observation:
                audio_path = self._save_audio(observation['audio'], step)
                if audio_path:
                    media_paths['audio'] = audio_path
            
            # Handle image content (for non-video modes)
            if isinstance(observation, dict) and 'image' in observation:
                image_path = self._save_image(observation['image'], step)
                if image_path:
                    media_paths['image'] = image_path
            
            # Build messages using your format
            messages = self._build_messages(observation, step, media_paths['video'], media_paths['audio'], media_paths['image'])
            
            # Prepare headers as per your format
            headers = {
                "Authorization": f"Bearer {self.api_key}",
                "Content-Type": "application/json"
            }
            
            # ðŸŽ¯ ä¿®æ”¹ï¼šç§»é™¤videoæ¨¡æ€ï¼Œå› ä¸ºæˆ‘ä»¬å·²ç»å°†è§†é¢‘è½¬æ¢ä¸ºå›¾åƒåºåˆ—
            payload = {
                "model": self.model_name,
                "messages": messages,
                "modalities": ["text", "audio"],  # ç§»é™¤videoï¼Œå› ä¸ºå·²è½¬æ¢ä¸ºå›¾åƒ
                "audio": {"voice": "Cherry", "format": "wav"},
                "stream": False,
                "max_tokens": 4098,
                "temperature": 0.1
            }
            
            # Log the request
            logger.info(f"Sending request to {self.api_base}/chat/completions")
            logger.debug(f"Payload modalities: {payload['modalities']}")
            logger.debug(f"Media files: {list(media_paths.keys())}")
            
            try:
                response = self.session.post(
                    f"{self.api_base}/chat/completions",
                    headers=headers,
                    json=payload,
                    timeout=300
                )
                
                if response.status_code == 200:
                    result = response.json()
                    response_text = result["choices"][0]["message"]["content"]
                    
                    logger.info(f"Model response received: {response_text[:100]}...")
                    
                    # Save the response
                    media_paths["response"] = self._save_model_response(response_text, step)
                    
                    # Save API input video content (what would be sent in video mode)
                    media_paths["api_input"] = self._save_api_input_video(observation, step)
                    
                    # Extract command from response
                    command = self._extract_command(response_text)
                    
                    return response_text, command, media_paths
                else:
                    error_msg = f"APIè¯·æ±‚å¤±è´¥: {response.status_code}"
                    logger.error(f"{error_msg}\né”™è¯¯ä¿¡æ¯: {response.text}")
                    return error_msg, np.array([0, 0, 50, 50], dtype=np.int32), media_paths
                    
            except requests.exceptions.Timeout:
                error_msg = "APIè¯·æ±‚è¶…æ—¶"
                logger.error(error_msg)
                return error_msg, np.array([0, 0, 50, 50], dtype=np.int32), media_paths
            except requests.exceptions.RequestException as e:
                error_msg = f"APIè¯·æ±‚å¼‚å¸¸: {e}"
                logger.error(error_msg)
                return error_msg, np.array([0, 0, 50, 50], dtype=np.int32), media_paths
                
        except Exception as e:
            logger.error(f"Model query failed: {e}")
            import traceback
            logger.error(f"Full traceback: {traceback.format_exc()}")
            # Return safe media_paths dict with all expected keys
            safe_media_paths = {
                "video": None,
                "audio": None,
                "image": None,
                "response": None,
                "api_input": None
            }
            return f"Error: {e}", np.array([0, 0, 50, 50], dtype=np.int32), safe_media_paths

    def _create_env_for_episode(self, episode_idx: int) -> CoopCommandGymEnv:
        """ä¸ºæŒ‡å®šepisodeåˆ›å»ºæ–°çš„çŽ¯å¢ƒå®žä¾‹"""
        try:
            # è®¡ç®—è¯¥episodeçš„seedï¼šåŸºç¡€seed + episodeç´¢å¼•ï¼Œç¡®ä¿æ¯ä¸ªepisodeç‹¬ç«‹
            episode_seed = self.seed_index + episode_idx * 1000
            
            # ç¡®å®šå½•åˆ¶ç›®å½•
            if self.save_media and episode_idx in self.episode_dirs:
                recordings_dir = str(self.episode_dirs[episode_idx]["videos"])
            else:
                recordings_dir = "recordings"
            
            # ç¡®å®šå½•åˆ¶æ¨¡å¼
            if self.input_mode == "video":
                recording_mode = "video"
            elif self.enhanced_video:
                recording_mode = "both"
            else:
                recording_mode = "individual"
            
            actual_fps = self.video_fps if self.enhanced_video else 1
            
            # åˆ›å»ºæ–°çš„çŽ¯å¢ƒå®žä¾‹
            env = CoopCommandGymEnv(
                difficulty=self.difficulty,
                seed_index=episode_seed,  # ä½¿ç”¨è®¡ç®—å‡ºçš„episode seed
                max_rounds=self.max_rounds,
                enable_audio=True,
                enable_visual=True,
                deterministic_commands=self.deterministic_commands,
                recording_mode=recording_mode,
                video_fps=actual_fps,
                enhanced_video=self.enhanced_video,
                audio_duration_per_frame=self.audio_duration_per_frame,
                recordings_dir=recordings_dir
            )
            
            logger.info(f"Created environment for episode {episode_idx} with seed {episode_seed}")
            return env
            
        except Exception as e:
            logger.error(f"Failed to create environment for episode {episode_idx}: {e}")
            raise

    def run_evaluation(self) -> Dict:
        """Run the multi-episode evaluation."""
        logger.info(f"Starting multi-episode evaluation - Provider: {self.api_provider.upper()}, Model: {self.model_name}")
        logger.info(f"Episodes: {self.num_episodes}, Difficulty: {self.difficulty}, Base Seed: {self.seed_index}")
        if self.save_media:
            logger.info(f"Media files will be saved to: {self.output_dir}")
        
        episode_results = []
        overall_command_compliance = {
            "total_turns": 0,
            "valid_single_commands": 0,
            "multiple_command_violations": 0,
            "no_command_found": 0,
            "compliance_rate": 0.0
        }
        
        # è¿è¡Œæ¯ä¸ªepisode
        for episode_idx in range(self.num_episodes):
            logger.info(f"\n{'='*60}")
            logger.info(f"ðŸŽ® STARTING EPISODE {episode_idx + 1}/{self.num_episodes}")
            logger.info(f"{'='*60}")
            
            try:
                # åˆ›å»ºæ–°çš„çŽ¯å¢ƒå®žä¾‹
                if self.env:
                    self.env.close()  # æ¸…ç†ä¹‹å‰çš„çŽ¯å¢ƒ
                self.env = self._create_env_for_episode(episode_idx)
                
                # è¿è¡Œå•ä¸ªepisode
                episode_result = self._run_single_episode(episode_idx)
                episode_results.append(episode_result)
                
                # æ›´æ–°æ•´ä½“æŒ‡æ ‡
                ep_compliance = episode_result.get("command_compliance", {})
                overall_command_compliance["total_turns"] += ep_compliance.get("total_turns", 0)
                overall_command_compliance["valid_single_commands"] += ep_compliance.get("valid_single_commands", 0)
                overall_command_compliance["multiple_command_violations"] += ep_compliance.get("multiple_command_violations", 0)
                overall_command_compliance["no_command_found"] += ep_compliance.get("no_command_found", 0)
                
                # è®°å½•episodeç»“æžœ
                logger.info(f"âœ… Episode {episode_idx + 1} completed:")
                logger.info(f"   Score: {episode_result['final_stats']['final_score_normalized']:.1f}/100")
                logger.info(f"   Steps: {episode_result['final_stats']['total_steps']}")
                logger.info(f"   Objectives: {episode_result['final_stats']['objectives_completed']}/{episode_result['final_stats']['total_objectives']}")
                logger.info(f"   Success Rate: {episode_result['final_stats']['success_rate']:.1%}")
                
            except Exception as e:
                logger.error(f"ðŸ’¥ Episode {episode_idx + 1} failed: {e}")
                logger.error(f"Full traceback: {traceback.format_exc()}")
                
                # åˆ›å»ºå¤±è´¥çš„episodeç»“æžœ
                episode_result = {
                    "episode_index": episode_idx,
                    "episode_seed": self.seed_index + episode_idx * 1000,
                    "status": "failed",
                    "error": str(e),
                    "steps": [],
                    "final_stats": {
                        "total_steps": 0,
                        "total_reward": 0.0,
                        "final_score_normalized": 0.0,
                        "objectives_completed": 0,
                        "total_objectives": 0,
                        "success_rate": 0.0,
                        "terminated": False,
                        "truncated": True
                    },
                    "command_compliance": {
                        "total_turns": 0,
                        "valid_single_commands": 0,
                        "multiple_command_violations": 0,
                        "no_command_found": 0,
                        "compliance_rate": 0.0
                    }
                }
                episode_results.append(episode_result)
            
            finally:
                # æ¸…ç†å½“å‰episodeçš„çŽ¯å¢ƒ
                if self.env:
                    try:
                        self.env.close()
                    except:
                        pass
                    self.env = None
        
        # è®¡ç®—æ•´ä½“åˆè§„çŽ‡
        if overall_command_compliance["total_turns"] > 0:
            overall_command_compliance["compliance_rate"] = (
                overall_command_compliance["valid_single_commands"] / 
                overall_command_compliance["total_turns"]
            )
        
        # è®¡ç®—æ±‡æ€»ç»Ÿè®¡
        summary_stats = self._calculate_summary_stats(episode_results)
        
        # æ›´æ–°ç»“æžœ
        self.results["episodes"] = episode_results
        self.results["summary_stats"] = summary_stats
        self.results["command_compliance"] = overall_command_compliance
        
        # è¾“å‡ºæœ€ç»ˆæŠ¥å‘Š
        self._log_final_report(summary_stats, overall_command_compliance)
        
        return self.results

    def _run_single_episode(self, episode_idx: int) -> Dict:
        """è¿è¡Œå•ä¸ªepisodeçš„è¯„ä¼°"""
        # é‡ç½®å½“å‰episodeçš„è¿½è¸ªå˜é‡
        current_episode_compliance = {
            "total_turns": 0,
            "valid_single_commands": 0,
            "multiple_command_violations": 0,
            "no_command_found": 0,
            "compliance_rate": 0.0
        }
        
        # é‡ç½®çŽ¯å¢ƒ
        try:
            observation, info = self.env.reset()
            logger.debug(f"Episode {episode_idx} environment reset successful")
        except Exception as e:
            logger.error(f"Episode {episode_idx} environment reset failed: {e}")
            raise
        
        episode_seed = self.seed_index + episode_idx * 1000
        logger.info(f"Episode {episode_idx + 1} - Score: {info.get('score_normalized', 0):.1f}/100, "
                   f"Max rounds: {info.get('max_rounds', 0)}, Seed: {episode_seed}")
        
        step_count = 0
        total_reward = 0
        steps = []
        
        while True:
            step_count += 1
            logger.debug(f"Episode {episode_idx + 1}, Step {step_count}")
            
            # èŽ·å–å½“å‰episodeçš„åª’ä½“ä¿å­˜ç›®å½•
            current_images_dir = self.episode_dirs[episode_idx]["images"] if episode_idx in self.episode_dirs else self.images_dir
            current_audio_dir = self.episode_dirs[episode_idx]["audio"] if episode_idx in self.episode_dirs else self.audio_dir
            current_videos_dir = self.episode_dirs[episode_idx]["videos"] if episode_idx in self.episode_dirs else self.videos_dir
            current_responses_dir = self.episode_dirs[episode_idx]["responses"] if episode_idx in self.episode_dirs else self.responses_dir
            
            # ä¸´æ—¶ä¿®æ”¹ä¿å­˜ç›®å½•
            orig_dirs = None
            if self.save_media:
                orig_dirs = (self.images_dir, self.audio_dir, self.videos_dir, self.responses_dir)
                self.images_dir = current_images_dir
                self.audio_dir = current_audio_dir  
                self.videos_dir = current_videos_dir
                self.responses_dir = current_responses_dir
            
            try:
                # Query model and save media files
                model_response, command, media_paths = self._query_model(observation, step_count)
                
                # æ¢å¤åŽŸå§‹ç›®å½•
                if orig_dirs:
                    self.images_dir, self.audio_dir, self.videos_dir, self.responses_dir = orig_dirs
                
                # Validate single command requirement and track compliance
                current_episode_compliance["total_turns"] += 1
                
                # Use improved command detection that filters out markdown formatting
                valid_command_lines = []
                all_command_lines = re.findall(r"COMMAND:\s*[^\n]+", model_response, re.IGNORECASE)
                
                for cmd_line in all_command_lines:
                    # Filter out markdown formatting that isn't a real command
                    if not re.match(r"COMMAND:\s*[\*\#\-\`]+", cmd_line, re.IGNORECASE):
                        # Check if it contains actual command content
                        if re.search(r"COMMAND:\s*(?:\w+(?:,\w+)*|all)\s+\w+", cmd_line, re.IGNORECASE):
                            valid_command_lines.append(cmd_line)
                
                command_count = len(valid_command_lines)
                
                if command_count > 1:
                    current_episode_compliance["multiple_command_violations"] += 1
                    logger.warning(f"âš ï¸ Multiple valid commands detected ({command_count}). Using first valid command.")
                elif command_count == 0:
                    current_episode_compliance["no_command_found"] += 1
                    logger.warning("âš ï¸ No valid COMMAND found in response. Using default command.")
                else:
                    current_episode_compliance["valid_single_commands"] += 1
                    logger.debug(f"âœ… Valid single command detected")
                
                # Set member list for multi-member commands before execution
                if hasattr(self, '_last_member_list') and self._last_member_list and command[0] == self.env.num_members + 1:
                    self.env.set_multi_member_list(self._last_member_list)
                
                # Execute command
                obs, reward, terminated, truncated, info = self.env.step(command)
                total_reward += reward
                
                # Generate proper command description
                try:
                    member_idx = int(command[0]) if len(command) > 0 else 0
                    cmd_idx = int(command[1]) if len(command) > 1 else 0
                    x = int(command[2]) if len(command) > 2 else 50
                    y = int(command[3]) if len(command) > 3 else 50
                    
                    if 0 <= cmd_idx < len(self.command_types):
                        cmd_type = self.command_types[cmd_idx]
                    else:
                        cmd_type = self.command_types[0]
                        
                except (IndexError, ValueError, TypeError) as e:
                    logger.error(f"Error parsing command array: {e}, command: {command}")
                    member_idx, cmd_idx, x, y = 0, 0, 50, 50
                    cmd_type = self.command_types[0]
                
                if member_idx == self.env.num_members:
                    command_desc = f"{cmd_type} to ({x},{y}) by all team members"
                elif member_idx == self.env.num_members + 1:
                    command_desc = f"{cmd_type} to ({x},{y}) by multiple members"
                else:
                    command_desc = f"{cmd_type} to ({x},{y}) by member {member_idx}"
                
                # Log step results with media paths
                step_result = {
                    "step": step_count,
                    "command": command.tolist(),
                    "command_desc": command_desc,
                    "reward": float(reward),
                    "total_reward": float(total_reward),
                    "score_normalized": float(info.get('score_normalized', 0)),
                    "rounds_remaining": info.get('rounds_remaining', 0),
                    "objectives_completed": info.get('objectives_completed', 0),
                    "model_response_length": len(model_response),
                    "terminated": terminated,
                    "truncated": truncated,
                    "media_paths": media_paths
                }
                
                steps.append(step_result)
                
                logger.debug(f"Episode {episode_idx + 1}, Step {step_count}: {command_desc}")
                logger.debug(f"Reward: {reward:.2f}, Total: {total_reward:.2f}, Score: {info.get('score_normalized', 0):.1f}/100")
                
                # Update observation
                observation = obs
                
                # Check termination
                if terminated or truncated:
                    logger.info(f"Episode {episode_idx + 1} ended - Terminated: {terminated}, Truncated: {truncated}")
                    break
                    
            except Exception as e:
                logger.error(f"Error in episode {episode_idx + 1}, step {step_count}: {e}")
                # æ¢å¤ç›®å½•ï¼ˆå¦‚æžœå‡ºé”™ï¼‰
                if orig_dirs:
                    self.images_dir, self.audio_dir, self.videos_dir, self.responses_dir = orig_dirs
                raise
        
        # Calculate episode compliance rate
        if current_episode_compliance["total_turns"] > 0:
            current_episode_compliance["compliance_rate"] = (
                current_episode_compliance["valid_single_commands"] / 
                current_episode_compliance["total_turns"]
            )
        
        # Final statistics for this episode
        final_stats = {
            "total_steps": step_count,
            "total_reward": float(total_reward),
            "final_score_normalized": float(info.get('score_normalized', 0)),
            "objectives_completed": info.get('objectives_completed', 0),
            "total_objectives": info.get('total_objectives', 0),
            "success_rate": info.get('objectives_completed', 0) / max(1, info.get('total_objectives', 1)),
            "terminated": terminated,
            "truncated": truncated
        }
        
        return {
            "episode_index": episode_idx,
            "episode_seed": episode_seed,
            "status": "completed",
            "steps": steps,
            "final_stats": final_stats,
            "command_compliance": current_episode_compliance
        }

    def _calculate_summary_stats(self, episode_results: List[Dict]) -> Dict:
        """è®¡ç®—æ‰€æœ‰episodeçš„æ±‡æ€»ç»Ÿè®¡"""
        if not episode_results:
            return {}
        
        # æ”¶é›†æ‰€æœ‰å·²å®Œæˆepisodeçš„ç»Ÿè®¡æ•°æ®
        completed_episodes = [ep for ep in episode_results if ep.get("status") == "completed"]
        failed_episodes = [ep for ep in episode_results if ep.get("status") == "failed"]
        
        if not completed_episodes:
            return {
                "total_episodes": len(episode_results),
                "completed_episodes": 0,
                "failed_episodes": len(failed_episodes),
                "success_rate": 0.0
            }
        
        # æå–å„é¡¹æŒ‡æ ‡
        scores = [ep["final_stats"]["final_score_normalized"] for ep in completed_episodes]
        steps = [ep["final_stats"]["total_steps"] for ep in completed_episodes]
        objectives_completed = [ep["final_stats"]["objectives_completed"] for ep in completed_episodes]
        total_objectives = [ep["final_stats"]["total_objectives"] for ep in completed_episodes]
        episode_success_rates = [ep["final_stats"]["success_rate"] for ep in completed_episodes]
        
        return {
            "total_episodes": len(episode_results),
            "completed_episodes": len(completed_episodes),
            "failed_episodes": len(failed_episodes),
            "completion_rate": len(completed_episodes) / len(episode_results),
            
            # åˆ†æ•°ç»Ÿè®¡
            "score_stats": {
                "mean": np.mean(scores),
                "std": np.std(scores),
                "min": np.min(scores),
                "max": np.max(scores),
                "median": np.median(scores)
            },
            
            # æ­¥æ•°ç»Ÿè®¡
            "steps_stats": {
                "mean": np.mean(steps),
                "std": np.std(steps),
                "min": np.min(steps),
                "max": np.max(steps),
                "median": np.median(steps)
            },
            
            # ç›®æ ‡å®Œæˆç»Ÿè®¡
            "objectives_stats": {
                "total_completed": sum(objectives_completed),
                "total_available": sum(total_objectives),
                "mean_completed_per_episode": np.mean(objectives_completed),
                "mean_success_rate": np.mean(episode_success_rates),
                "episodes_with_100_percent": sum(1 for rate in episode_success_rates if rate >= 1.0),
                "episodes_with_50_percent_plus": sum(1 for rate in episode_success_rates if rate >= 0.5)
            },
            
            # æ•´ä½“æˆåŠŸæŒ‡æ ‡
            "overall_success_rate": np.mean(episode_success_rates),
            "consistency": 1.0 - (np.std(scores) / 100.0),  # ä¸€è‡´æ€§æŒ‡æ ‡ (åˆ†æ•°æ ‡å‡†å·®çš„å€’æ•°)
        }

    def _log_final_report(self, summary_stats: Dict, overall_command_compliance: Dict):
        """è¾“å‡ºæœ€ç»ˆè¯„ä¼°æŠ¥å‘Š"""
        logger.info(f"\n{'='*80}")
        logger.info(f"ðŸ† MULTI-EPISODE EVALUATION REPORT")
        logger.info(f"{'='*80}")
        
        # åŸºç¡€ä¿¡æ¯
        logger.info(f"API Provider: {self.api_provider.upper()}, Model: {self.model_name}")
        logger.info(f"Episodes: {summary_stats.get('total_episodes', 0)} total, "
                   f"{summary_stats.get('completed_episodes', 0)} completed, "
                   f"{summary_stats.get('failed_episodes', 0)} failed")
        logger.info(f"Completion Rate: {summary_stats.get('completion_rate', 0):.1%}")
        
        # åˆ†æ•°ç»Ÿè®¡
        if "score_stats" in summary_stats:
            score_stats = summary_stats["score_stats"]
            logger.info(f"\nðŸ“Š SCORE STATISTICS:")
            logger.info(f"  Mean Score: {score_stats['mean']:.1f}/100 (Â±{score_stats['std']:.1f})")
            logger.info(f"  Score Range: {score_stats['min']:.1f} - {score_stats['max']:.1f}")
            logger.info(f"  Median Score: {score_stats['median']:.1f}/100")
        
        # ç›®æ ‡å®Œæˆç»Ÿè®¡
        if "objectives_stats" in summary_stats:
            obj_stats = summary_stats["objectives_stats"]
            logger.info(f"\nðŸŽ¯ OBJECTIVES STATISTICS:")
            logger.info(f"  Overall Success Rate: {obj_stats['mean_success_rate']:.1%}")
            logger.info(f"  Total Objectives Completed: {obj_stats['total_completed']}/{obj_stats['total_available']}")
            logger.info(f"  Episodes with 100% Success: {obj_stats['episodes_with_100_percent']}/{summary_stats['total_episodes']}")
            logger.info(f"  Episodes with 50%+ Success: {obj_stats['episodes_with_50_percent_plus']}/{summary_stats['total_episodes']}")
        
        # æ•ˆçŽ‡ç»Ÿè®¡
        if "steps_stats" in summary_stats:
            steps_stats = summary_stats["steps_stats"]
            logger.info(f"\nâš¡ EFFICIENCY STATISTICS:")
            logger.info(f"  Mean Steps per Episode: {steps_stats['mean']:.1f} (Â±{steps_stats['std']:.1f})")
            logger.info(f"  Steps Range: {steps_stats['min']:.0f} - {steps_stats['max']:.0f}")
        
        # ä¸€è‡´æ€§è¯„ä¼°
        consistency = summary_stats.get('consistency', 0)
        logger.info(f"\nðŸŽ² CONSISTENCY ANALYSIS:")
        logger.info(f"  Performance Consistency: {consistency:.1%}")
        if consistency >= 0.8:
            logger.info(f"  âœ… High consistency - Stable performance across episodes")
        elif consistency >= 0.6:
            logger.info(f"  âš ï¸ Moderate consistency - Some performance variation")
        else:
            logger.info(f"  âŒ Low consistency - High performance variation")
        
        # å‘½ä»¤åˆè§„æ€§æŠ¥å‘Š
        compliance = overall_command_compliance
        logger.info(f"\nðŸ”§ COMMAND COMPLIANCE REPORT:")
        logger.info(f"  Total Turns: {compliance['total_turns']}")
        logger.info(f"  Valid Single Commands: {compliance['valid_single_commands']}")
        logger.info(f"  Multiple Command Violations: {compliance['multiple_command_violations']}")
        logger.info(f"  No Command Found: {compliance['no_command_found']}")
        logger.info(f"  Overall Compliance Rate: {compliance['compliance_rate']:.1%}")
        
        if compliance['compliance_rate'] < 1.0:
            violation_rate = 100 - compliance['compliance_rate']*100
            logger.warning(f"  âš ï¸ Model violated single command constraint in {violation_rate:.1f}% of turns!")
        else:
            logger.info(f"  âœ… Perfect command compliance achieved across all episodes!")
        
        logger.info(f"{'='*80}")

    def _convert_numpy_types(self, obj):
        """é€’å½’è½¬æ¢NumPyç±»åž‹ä¸ºPythonåŽŸç”Ÿç±»åž‹ï¼Œä½¿å…¶å¯ä»¥JSONåºåˆ—åŒ–"""
        if isinstance(obj, np.integer):
            return int(obj)
        elif isinstance(obj, np.floating):
            return float(obj)
        elif isinstance(obj, np.ndarray):
            return obj.tolist()
        elif isinstance(obj, dict):
            return {key: self._convert_numpy_types(value) for key, value in obj.items()}
        elif isinstance(obj, list):
            return [self._convert_numpy_types(item) for item in obj]
        elif isinstance(obj, tuple):
            return tuple(self._convert_numpy_types(item) for item in obj)
        else:
            return obj

    def save_results(self, filename: Optional[str] = None) -> str:
        """Save multi-episode results to JSON file."""
        if filename is None:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            filename = f"{self.api_provider}_eval_{self.difficulty}_seed{self.seed_index}_{self.num_episodes}ep_{timestamp}.json"
        
        # Save in output directory if media saving is enabled
        if self.save_media:
            filepath = self.output_dir / "results.json"
        else:
            filepath = Path(filename)
        
        # Add summary of media files to results
        if self.save_media:
            total_images = sum(len(ep.get("steps", [])) for ep in self.results["episodes"])
            total_videos = len([ep for ep in self.results["episodes"] if ep.get("status") == "completed"])
            
            self.results["media_summary"] = {
                "total_episodes": len(self.results["episodes"]),
                "total_images_across_episodes": total_images,
                "total_videos_across_episodes": total_videos, 
                "output_directory": str(self.output_dir),
                "episode_directories": {
                    f"episode_{i:02d}": str(self.episode_dirs[i]["root"]) 
                    for i in range(len(self.results["episodes"]))
                    if i in self.episode_dirs
                }
            }
        
        # è½¬æ¢NumPyç±»åž‹ä¸ºJSONå¯åºåˆ—åŒ–ç±»åž‹
        json_safe_results = self._convert_numpy_types(self.results)
        
        with open(filepath, 'w', encoding='utf-8') as f:
            json.dump(json_safe_results, f, indent=2, ensure_ascii=False)
        
        logger.info(f"Multi-episode results saved to: {filepath.absolute()}")
        if self.save_media:
            logger.info(f"Media files directory structure:")
            logger.info(f"  Root: {self.output_dir.absolute()}")
            logger.info(f"  Episodes: {len(self.results['episodes'])} episode subdirectories")
            logger.info(f"  Total Steps: {sum(len(ep.get('steps', [])) for ep in self.results['episodes'])}")
        
        return str(filepath)

    def close(self):
        """Clean up resources."""
        self.env.close()

    def _save_video(self, video_data: str, step: int) -> Optional[str]:
        """Save video data to file"""
        if not self.save_media or not video_data:
            return None
        
        try:
            # Decode base64 video data
            video_bytes = base64.b64decode(video_data)
            
            # Save to file
            video_path = self.videos_dir / f"step_{step:03d}_video.mp4"
            with open(video_path, 'wb') as f:
                f.write(video_bytes)
            
            return str(video_path)
        except Exception as e:
            logger.error(f"Failed to save video for step {step}: {e}")
            return None

    def _save_audio(self, audio_data: str, step: int) -> Optional[str]:
        """Save audio data to file"""
        if not self.save_media or not audio_data:
            return None
        
        try:
            # Check if it's base64 encoded audio or JSON text
            if audio_data.startswith('{'):
                # JSON format - save as text file
                audio_path = self.audio_dir / f"step_{step:03d}_audio.json"
                with open(audio_path, 'w', encoding='utf-8') as f:
                    f.write(audio_data)
            else:
                # Base64 encoded audio - save as audio file
                audio_bytes = base64.b64decode(audio_data)
                audio_path = self.audio_dir / f"step_{step:03d}_audio.mp3"
                with open(audio_path, 'wb') as f:
                    f.write(audio_bytes)
            
            return str(audio_path)
        except Exception as e:
            logger.error(f"Failed to save audio for step {step}: {e}")
            return None

    def _save_image(self, image_data, step: int) -> Optional[str]:
        """Save image data to file"""
        if not self.save_media or image_data is None:
            return None
        
        try:
            from PIL import Image
            import io
            
            if isinstance(image_data, str):
                # Base64 encoded image
                image_bytes = base64.b64decode(image_data)
                image = Image.open(io.BytesIO(image_bytes))
            elif hasattr(image_data, 'shape'):
                # Numpy array
                image = Image.fromarray(image_data.astype(np.uint8))
            else:
                return None
            
            # Save to file
            image_path = self.images_dir / f"step_{step:03d}_image.jpg"
            image.save(image_path, 'JPEG', quality=85)
            
            return str(image_path)
        except Exception as e:
            logger.error(f"Failed to save image for step {step}: {e}")
            return None

    def _save_model_response(self, response_text: str, step: int) -> Optional[str]:
        """Save model response to file"""
        if not self.save_media or not response_text:
            return None
        
        try:
            response_path = self.responses_dir / f"step_{step:03d}_response.txt"
            with open(response_path, 'w', encoding='utf-8') as f:
                f.write(response_text)
            
            return str(response_path)
        except Exception as e:
            logger.error(f"Failed to save response for step {step}: {e}")
            return None

    def _save_api_input_video(self, observation, step: int) -> Optional[str]:
        """Save API input video content"""
        if not self.save_media:
            return None
        
        try:
            # Create a summary of what would be sent to the API
            api_input_summary = {
                "step": step,
                "observation_type": type(observation).__name__,
                "modalities_included": []
            }
            
            if isinstance(observation, dict):
                if 'video' in observation and observation['video']:
                    api_input_summary["modalities_included"].append("video")
                    api_input_summary["video_size_bytes"] = len(observation['video'])
                
                if 'audio' in observation and observation['audio']:
                    api_input_summary["modalities_included"].append("audio")
                    api_input_summary["audio_size_bytes"] = len(observation['audio'])
                
                if 'image' in observation:
                    api_input_summary["modalities_included"].append("image")
                
                if 'vector' in observation:
                    api_input_summary["modalities_included"].append("vector")
                    api_input_summary["vector_shape"] = list(observation['vector'].shape)
            
            # Save summary
            api_input_path = self.output_dir / "api_inputs" / f"step_{step:03d}_api_input.json"
            api_input_path.parent.mkdir(exist_ok=True)
            
            with open(api_input_path, 'w', encoding='utf-8') as f:
                json.dump(api_input_summary, f, indent=2)
            
            return str(api_input_path)
        except Exception as e:
            logger.error(f"Failed to save API input summary for step {step}: {e}")
            return None

    def _extract_command(self, response_text: str) -> np.ndarray:
        """Extract command from model response"""
        try:
            # Look for COMMAND: pattern
            command_pattern = r"COMMAND:\s*([^\n]+)"
            matches = re.findall(command_pattern, response_text, re.IGNORECASE)
            
            if not matches:
                logger.warning("No COMMAND found in response, using default")
                return np.array([0, 0, 50, 50], dtype=np.int32)
            
            # Use first command found
            command_str = matches[0].strip()
            logger.debug(f"Found command: {command_str}")
            
            # Parse command string
            parts = command_str.split()
            if len(parts) < 3:
                logger.warning(f"Invalid command format: {command_str}")
                return np.array([0, 0, 50, 50], dtype=np.int32)
            
            # Handle different member selection formats
            member_part = parts[0]
            action = parts[1]
            
            # Parse member selection
            if member_part.lower() == "all":
                member_idx = self.env.num_members  # Team command
            elif "," in member_part:
                # Multi-member command like "0,1,2"
                member_indices = [int(x.strip()) for x in member_part.split(",") if x.strip().isdigit()]
                self._last_member_list = member_indices
                member_idx = self.env.num_members + 1  # Multi-member command
            else:
                # Single member
                try:
                    member_idx = int(member_part)
                except ValueError:
                    logger.warning(f"Invalid member index: {member_part}")
                    member_idx = 0
            
            # Parse action
            action_map = {cmd: i for i, cmd in enumerate(self.command_types)}
            cmd_idx = action_map.get(action.lower(), 0)
            
            # Parse coordinates
            if len(parts) >= 4:
                try:
                    x = max(0, min(100, int(float(parts[2]))))
                    y = max(0, min(100, int(float(parts[3]))))
                except ValueError:
                    x, y = 50, 50
            else:
                x, y = 50, 50
            
            return np.array([member_idx, cmd_idx, x, y], dtype=np.int32)
            
        except Exception as e:
            logger.error(f"Error extracting command: {e}")
            return np.array([0, 0, 50, 50], dtype=np.int32)

def parse_args():
    parser = argparse.ArgumentParser(description="Multi-Episode Cooperative Command Game Evaluation")
    parser.add_argument("--difficulty", type=str, default="medium", choices=["normal", "medium", "hard"])
    parser.add_argument("--seed_index", type=int, default=0)
    parser.add_argument("--max_rounds", type=int, default=100, help="Maximum rounds for the game (default: 100)")
    parser.add_argument("--save_media", action="store_true", default=True, help="Save media files (default: True)")
    parser.add_argument("--probabilistic_commands", action="store_true")
    parser.add_argument("--api_provider", type=str, default="qwen", choices=["qwen", "openai"],
                        help="API provider to use")
    parser.add_argument("--model_name", type=str, default=None,
                        help="Model name (defaults to provider's default model)")
    parser.add_argument("--no_stream", action="store_true",
                        help="Disable streaming responses")
    parser.add_argument("--input_mode", type=str, default="video", 
                        choices=["image_audio", "video"],
                        help="Input modality mode: 'image_audio' for separate image and audio inputs, 'video' for video input")
    parser.add_argument("--no_vector_text", action="store_true",
                        help="Exclude vector information from text prompt (rely on visual interpretation only)")
    parser.add_argument("--enhanced_video", action="store_true",
                        help="Enable enhanced video recording with integrated audio")
    parser.add_argument("--video_fps", type=float, default=0.5,
                        help="Frames per second for video recording (default: 0.5 for audio integration)")
    parser.add_argument("--audio_duration_per_frame", type=float, default=3.0,
                        help="Expected audio duration per frame in seconds (default: 3.0)")
    # æ–°å¢žå‚æ•°
    parser.add_argument("--num_episodes", type=int, default=10,
                        help="Number of episodes to evaluate (default: 10)")
    return parser.parse_args()

def main():
    args = parse_args()
    difficulty = args.difficulty
    seed_index = args.seed_index
    max_rounds = args.max_rounds
    save_media = args.save_media
    probabilistic_commands = args.probabilistic_commands
    api_provider = args.api_provider
    model_name = args.model_name
    enable_stream = not args.no_stream
    input_mode = args.input_mode
    include_vector_text = not args.no_vector_text
    enhanced_video = args.enhanced_video
    video_fps = args.video_fps
    audio_duration_per_frame = args.audio_duration_per_frame
    num_episodes = args.num_episodes  # æ–°å¢ž
    
    # Display configuration
    print(f"\nðŸš€ Multi-Episode Evaluation Configuration")
    print(f"ðŸ“ API Provider: {api_provider.upper()}")
    if model_name:
        print(f"ðŸ¤– Model: {model_name}")
    else:
        print(f"ðŸ¤– Model: {MODEL_CHAT} (default)")
    print(f"ðŸŽ® Difficulty: {difficulty.upper()}, Base Seed: {seed_index}")
    print(f"ðŸ”„ Episodes: {num_episodes}")  # æ–°å¢ž
    print(f"ðŸŽ¯ Max Rounds per Episode: {max_rounds}")
    print(f"ðŸ’¾ Save Media: {'Yes' if save_media else 'No'}")
    print(f"ðŸŽ¯ Command Execution: {'Probabilistic' if probabilistic_commands else 'Deterministic'}")
    print(f"ðŸ”„ Streaming: {'Enabled' if enable_stream else 'Disabled'}")
    print(f"ðŸŽ¬ Input Mode: {input_mode.upper()}")
    print(f"ðŸ“Š Include Vector Text: {'Yes' if include_vector_text else 'No'}")
    print(f"ðŸŽ¥ Enhanced Video: {'Yes' if enhanced_video else 'No'}")
    print(f"ðŸŽ¥ Video FPS: {video_fps}")
    print(f"ðŸŽ¤ Audio Duration per Frame: {audio_duration_per_frame}s")
    
    print(f"ðŸ‘ï¸  Vision: Supported ({input_mode} input)")
    print("=" * 60)
    
    # Run evaluation
    evaluator = MultiProviderEvaluator(
        difficulty=difficulty,
        seed_index=seed_index,
        max_rounds=max_rounds,
        enable_stream=enable_stream,
        save_media=save_media,
        deterministic_commands=not probabilistic_commands,
        api_provider=api_provider,
        model_name=model_name,
        input_mode=input_mode,
        include_vector_text=include_vector_text,
        enhanced_video=enhanced_video,
        video_fps=video_fps,
        audio_duration_per_frame=audio_duration_per_frame,
        num_episodes=num_episodes  # æ–°å¢ž
    )
    
    try:
        results = evaluator.run_evaluation()
        filepath = evaluator.save_results()
        
        print(f"\nâœ… Multi-episode evaluation completed!")
        print(f"ðŸ“„ Results saved to: {filepath}")
        print(f"ðŸ“ˆ Episodes: {results['summary_stats'].get('completed_episodes', 0)}/{results['summary_stats'].get('total_episodes', 0)}")
        print(f"ðŸ† Mean Score: {results['summary_stats'].get('score_stats', {}).get('mean', 0):.1f}/100")
        print(f"ðŸŽ¯ Overall Success Rate: {results['summary_stats'].get('objectives_stats', {}).get('mean_success_rate', 0):.1%}")
        print(f"ðŸŽ® Provider: {api_provider.upper()}, Model: {evaluator.model_name}")
        
    except KeyboardInterrupt:
        print("\nâ›” Multi-episode evaluation interrupted by user")
    except Exception as e:
        logger.error(f"ðŸ’¥ Multi-episode evaluation failed: {e}")
        logger.error(f"Full traceback: {traceback.format_exc()}")
    finally:
        if hasattr(evaluator, 'env') and evaluator.env:
            evaluator.env.close()

if __name__ == "__main__":
    main()